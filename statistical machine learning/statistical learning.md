# Statistical Learning

## 1.统计学习先验知识

### 1.1相关定义

**输入空间**：将输入所有可能的取值的集合

**输出空间**：输出所有可能的取值的集合

**特征空间**：所以特征向量存在的空间，每一维对应于一个特征

**假设空间**：模型将输入到输出空间进行映射 ，该映射的集合就是假设空间。通常用$F$​表示，$F$通常可以定义为决策函数的集合和条件概率的集合
$$
F = {\{f|y = f(x)\}} 决策函数\\
F = {\{P|P(Y|X)\}} 条件概率\\
$$
$F$通常是由一个参数向量$\theta $决定的函数族或者分布族

参数$\theta$​ 取值与$n$​维欧式空间也叫**参数空间**

模型分为概率模型(条件概率$P(X|Y)$)和非概率模型(决策函数$Y = f(x)$)

### 1.2联合概率分布

对于随机变量$x,y$ 

联合概率$P(X，Y) = {S_{X \cap Y} \over S_{all}}$：表示在$x=X，y=Y$条件下的概率

条件概率$P(X|Y) = {S_{X \cap Y} \over S_Y}$：表示在$y=Y条件下x=X$的概率

贝叶斯公式：$P(X,Y) = P(X|Y)*P(Y)$

条件和结果可以互换：
$$
P(X,Y) = P(Y,X) \Rightarrow P(X|Y)*P(Y) = P(Y|X) *P(X) \tag 1
$$
对于$(1)$​只需要知道其中三个因子就能求出第四个，对上式做变形即可得到贝叶斯公式
$$
P(X|Y) = {P(Y|X) * P(X) \over P(Y)} \tag 2
$$

### 1.3决策

损失函数用来衡量模型的预测的好坏，模型越准确预测的值与真实的差距越小

#### 1.3.1损失函数

##### 0-1损失

$$
L(Y,f(X)) = \begin{cases}
0, & Y=f(X) \\
1, & Y \neq f(X) \\
\end{cases} \tag 1
$$

##### 平方损失函数

$$
L(Y,f(X)) = (Y-f(X))^2 \tag 2
$$

##### 绝对损失函数

$$
L(Y,f(X)) = |Y-f(X)| \tag 3
$$

##### 对数损失

$$
L(Y,P(Y|X)) = -logP(Y|X) \tag 4
$$

其中$(1),(2),(3)$​是衡量决策函数损失的，$(4)$​是衡量概率函数损失的

###### 期望(均值)：反应随机变量均值的指标

对于离散型变量$X = x_1,x_2,x_3,\ldots x_n$ 分别对应的概率为$Y = p(x_1),p(x_2),\ldots,p(x_n)$

那么随机变量$X$的期望$E(X) = \sum_{i=1}^n x_{i}p(x_i)$

对于连续型变量$X$的概率密度函数为 $f(X)$ 那么期望为$E(x) = \int_{-\infty}^{\infty} Xf(X)$

所以损失函数的期望是：
$$
R_{exp} = E_{p}[L(Y,f(X))] = \int_{X,Y} L(y,f(x)) p(x,y) dxdy \tag 5
$$
上述式子$(5)$ 即为**风险函数/期望损失** 

学习的目标就是选择期**望风险最小**的模型

**经验风险/经验损失**：训练数据集的平均损失
$$
R_{emp}(f) = {1 \over N} \sum_{i=1}^NL(y_i,f(x_i)) \tag 6
$$
当样本数量足够多的时候，更具大数定律$R_{emp}(f) \rightarrow R_{exp}$

#### 1.3.2 经验风险最小化和结构风险最小化

**经验风险最小化**：经验风险最小的模型是最优模型

**结构风险最小化**：防止在样本数量少的情况下，经验风险最小化过拟合

