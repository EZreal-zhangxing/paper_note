# Faster RCNN

## 1.RCNN

1. 每张图片使用selective search方法生成1k-2k个候选区域

2. 对于生成的候选区(2k个)，对每个候选区域的图像缩放到$227 \times 227$ 然后输入预训练好的AlexNet网络，使用深度网络提取特征。获得4096维的特征，最后输出$2k \times 4096$维的矩阵

3. $2k \times 4096$ 特征向量输入20个SVM分类器最后获得$2000 \times 20$，判别是否属于该类，然后对每一列即每一类别的框进行NMS(非极大值抑制)去除重叠的建议框，得到该类别中得分最高的一些建议框

4. 对第3步NMS处理后的剩余框对应的特征向量，使用20个回归器对剩余的建议框进行回归操作，修正候选框的位置。最终得到每个类别的修正后的得分最高的bounding box

### NMS(非极大值抑制)

```
while{
	1.寻找得分最高的目标
	2.计算其他目标与该目标的iou值
	3.删除所有IOU值大于给定阈值的目标
}
```

[源码](file:///Users/zhangxing/笔记/statistical machine learning/NMS.md)

### Selective Search

参考[目标检测-selective search](https://zhuanlan.zhihu.com/p/27467369)

论文Selective search Draft

## 2.Fast R-CNN

1. 每张图片使用selective search方法生成1k-2k个候选区域
2. 将图像输入网络得到相应的特征图，将Selective Search生成的候选框投影到特征图像上获取对应的特征矩阵
3. 将每个特征矩阵通过ROI pooling 层缩放到$7 \times 7$大小的特征图，然后输入两个全连接层展平，之后在并联两个全连接层，分别预测类别$(N + 1)背景类别+所有类别$ 和做bbox回归得到预测结果

### 模型训练-采样

并不是全部采用SS算法计算的候选框区域进行训练，而是有正负样本采样，从2k个候选框中采集64个候选框，如果候选框与Groundtruth的IOU大于阈值0.5 那么就归为正样本，其中正负样本的比例为$1:3$

### ROI Pooling layer

将候选框所在的特征图，均分成$7 \times 7$大小，然后通过最大池化层进行下采样

### 类别回归器

输出类别个数为$背景+所有样本类别 = 1 + N $

### 边界框回归器

输出维度为 $(N+1) \times 4$ 每个类别对应每个框的四个参数$(d_x,d_y,d_w,d_h)$

通过预测的回归框参数通过如下公式得到最终的边界框
$$
\hat G_x = P_w d_x(P) + P_x \\
\hat G_y = P_h d_y(P) + P_y \\
\hat G_w = P_w \exp(d_w(P)) \\
\hat G_h = P_h \exp(d_h(P)) \\
$$
$P_x,P_y,P_w,P_h$ 分别为候选框的中心$x,y$坐标，以及宽高

$ \hat G_x,\hat G_y,\hat G_w,\hat G_h$分别为最终预测边界框中心$x,y$坐标，以及宽高

$ d_x,d_y,d_w,d_h$分别为边界框的回归结果参数

