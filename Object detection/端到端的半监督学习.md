# 端到端的半监督学习

## Abstract

端到端的训练会逐渐提高伪标签的质量，越来越精确的伪标签反过来作用于目标检测的训练

我们提出了两个技术：

1. 一个soft teacher，每个未打标签的bounding box通过soft teacher网络进行分类打分并通过分数加权得到分类损失
2. 一个为框回归选择可靠伪框的框抖动方法(box jittering apporach)

## Introduction

对于半监督的目标检测，我们考虑基于伪标签的方法。伪标签方法是当前效果最好的方法。

[[27](#27),[36](#36)考虑的是多阶段的训练，在第一阶段，使用有标签的数据对检测器进行初始化训练,其次是对伪标签处理的过程，然后是基于伪标签的重新训练。多阶段的方法可以达到很高的准确率，但是最后的效果受限于伪标签的质量和小部分数据训练出来的检测器并不是那么的精准。

所以我们提出了一个端到端的目标检测框架，进行伪标签标记的同时，在每次迭代时使用伪标签数据和部分有标签的数据进行训练。标签数据和伪标签数据通过预设的比例进行采样合成一个batch的数据。这个数据会应用到两个模型，一个是检测的训练（学生），另一个是伪标签的标记（老师）。老师模型是学生模型的[EMA](#ema)（指数移动平均）。

老师模型会评估所有学生模型生成的候选框，而不是给类别标签提供伪框和给候选框回归向量。直接评估会使得更广泛的监督信息应用到学生模型训练。特别地说，我们先对候选框通过有高前景阈值的检测分数分类为前景或者背景（算法[27](#27)），这个高的前景阈值会导致一些正例框被错误的分类到了背景。为了解决这个问题，我们提出了使用可靠的测量来计算背景框的损失。我们发现教师模型的检测检测分数可以很好的作为可靠性度量





## Reference

<a name="27">A simple semi-supervised learning framework for object detection.</a>

<a name ="36">Rethinking pre-training and self-training.</a>





## 补充：<a name = "ema">EMA(指数移动平均)</a>

以指数递减的加权移动平均，用来估计变量的局部均值。

#### 1.加权平均

对于$N$个参数$(a_1,a_2,\ldots , a_n)$,加权平均为：
$$
V_{aver} = {1 \over N} \sum_{i=1}^N a_i
$$

#### 2.指数移动平均

$$
v_t = \beta v_{t-1} + (1- \beta)\theta_t \tag{1}
$$

$v_t$ 约等于最近的$1 \over 1-\beta $天的平均天气

$\theta_t$ 第t个参数值

$\beta$超参

将$\beta= 0.9$ 带入公式$(1)$求得
$$
v_{100} = 0.1 \theta_{100}+0.1\times 0.9 \theta_{99}+0.1\times0.9^2 \theta_{98} + \cdots + 0.1\times 0.9^{99} \theta_1
$$
所以$v$实际上是对最近的参数进行加权，距离当前$v$越近的参数权重越大。可以看到对于越远的参数，衰减是指数式的。